{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "db8a1d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"processed_valorant_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "d3d55acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1643, 73)\n",
      "\n",
      "Missing values:\n",
      "R2 score advantage: 345\n",
      "Match Result: 0\n",
      "Rolling round diff: 43\n",
      "Recent form: 0\n",
      "\n",
      "Clean dataset: 1298 matches\n"
     ]
    }
   ],
   "source": [
    "### Features Implemented:\n",
    "# 1. Average Team Rating 2.0 Score Advantage (20d Rolling)\n",
    "# 2. H2H Advantage (20d Rolling)\n",
    "# 3. Round Difference (20d Rolling)\n",
    "# 4. Recent Form (Last 5 Matches, 30d limit)\n",
    "\n",
    "### Initiating R2 Advantage Feature ###\n",
    "num = 20\n",
    "df['r2_advantage'] = df[f'rolling_{num}d_my'] - df[f'rolling_{num}d_opp']\n",
    "\n",
    "# data check\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "# missing values check\n",
    "print(f\"\\nMissing values:\")\n",
    "print(f\"R2 score advantage: {df['r2_advantage'].isna().sum()}\")\n",
    "print(f\"Match Result: {df['result'].isna().sum()}\")\n",
    "print(f\"Rolling round diff: {df['rolling_round_diff'].isna().sum()}\")\n",
    "print(f\"Recent form: {df['recent_form'].isna().sum()}\")\n",
    " \n",
    "# Note: Rolling round diff has 43 missing values due to shift = 1 on each team\n",
    "\n",
    "# removing matches including missing vals from key features (h2h irrelevant, will always be calculated)\n",
    "clean_df = df.dropna(subset=['r2_advantage', 'result', 'rolling_round_diff', 'recent_form'])\n",
    "print(f\"\\nClean dataset: {len(clean_df)} matches\")\n",
    "\n",
    "# peek at feature #1\n",
    "# print(f\"\\nR2 Advantage stats:\")\n",
    "# print(df['r2_advantage'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d5d36917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted target variable:\n",
      "Train wins: 550/1037 (0.530)\n",
      "Test wins: 131/261 (0.502)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/0ttm8wnn2hx0rydcd55zy81r0000gn/T/ipykernel_15247/4216998479.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['date'] = pd.to_datetime(clean_df['date'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Converting dates collected to Datetime format for features ###\n",
    "clean_df['date'] = pd.to_datetime(clean_df['date'])\n",
    "clean_df = clean_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "\n",
    "### Doing an 80/20 split for train/test sets ###\n",
    "split_date = clean_df['date'].quantile(0.8)\n",
    "train_df = clean_df[clean_df['date'] < split_date]\n",
    "test_df = clean_df[clean_df['date'] >= split_date]  \n",
    "\n",
    " \n",
    "X_train = train_df[['r2_advantage', 'rolling_round_diff', 'recent_form', 'h2h_advantage']]\n",
    "X_test = test_df[['r2_advantage', 'rolling_round_diff', 'recent_form', 'h2h_advantage']]\n",
    "y_train = train_df['result']\n",
    "y_test = test_df['result'] \n",
    "\n",
    "y_train_numeric = (y_train == 'W').astype(int)\n",
    "y_test_numeric = (y_test == 'W').astype(int)\n",
    "\n",
    "\n",
    "\n",
    "### Verifying data is balanced & clean ###\n",
    "print(\"Converted target variable:\")\n",
    "print(f\"Train wins: {y_train_numeric.sum()}/{len(y_train_numeric)} ({y_train_numeric.mean():.3f})\")\n",
    "print(f\"Test wins: {y_test_numeric.sum()}/{len(y_test_numeric)} ({y_test_numeric.mean():.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "64e58510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL RESULTS:\n",
      "Train Accuracy: 0.557\n",
      "Test Accuracy: 0.605\n",
      "Feature Coefficient: 1.076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train_numeric)\n",
    "\n",
    "train_pred = model.predict(X_train)\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train_numeric, train_pred)\n",
    "test_accuracy = accuracy_score(y_test_numeric, test_pred)\n",
    "\n",
    "print(f\"MODEL RESULTS:\")\n",
    "print(f\"Train Accuracy: {train_accuracy:.3f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
    "print(f\"Feature Coefficient: {model.coef_[0][0]:.3f}\")\n",
    "\n",
    "\n",
    "# Check if accuracy varies by team, date, or tournament\n",
    "#print(clean_df.groupby('team_name')['result'].apply(lambda x: (x=='W').mean()).sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "49894e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPREHENSIVE MODEL VALIDATION ===\n",
      "\n",
      "1. INDIVIDUAL FEATURE PREDICTIVE POWER:\n",
      "r2_advantage:\n",
      "  Solo Train: 0.556, Solo Test: 0.552, Gap: -0.005\n",
      "rolling_round_diff:\n",
      "  Solo Train: 0.560, Solo Test: 0.567, Gap: +0.007\n",
      "recent_form:\n",
      "  Solo Train: 0.554, Solo Test: 0.544, Gap: -0.009\n",
      "h2h_advantage:\n",
      "  Solo Train: 0.547, Solo Test: 0.536, Gap: -0.010\n",
      "\n",
      "2. TIME-BASED CROSS VALIDATION:\n",
      "  Fold 1: Train 0.592, Val 0.542, Gap -0.050\n",
      "  Fold 2: Train 0.565, Val 0.565, Gap +0.000\n",
      "  Fold 3: Train 0.589, Val 0.519, Gap -0.071\n",
      "  Fold 4: Train 0.561, Val 0.574, Gap +0.013\n",
      "  Fold 5: Train 0.567, Val 0.606, Gap +0.040\n",
      "  CV Mean: 0.561 ± 0.030\n",
      "\n",
      "3. RANDOM BASELINE COMPARISON:\n",
      "Random baseline - Train: 0.530, Test: 0.502\n",
      "Model improvement over random: 0.034\n",
      "\n",
      "4. FEATURE IMPORTANCE ANALYSIS:\n",
      "  r2_advantage: 1.0761\n",
      "  rolling_round_diff: 0.0042\n",
      "  recent_form: 0.1130\n",
      "  h2h_advantage: 0.6439\n",
      "\n",
      "5. MODEL STABILITY TEST (Bootstrap):\n",
      "  Bootstrap test scores: 0.583 ± 0.015\n",
      "  Your model vs bootstrap mean: -0.046\n",
      "\n",
      "6. H2H VALIDATION:\n",
      "  Early period H2H mean: 0.493\n",
      "  Recent period H2H mean: 0.489\n",
      "  Early period default H2H: 94.9%\n",
      "  Recent period default H2H: 75.3%\n",
      "\n",
      "7. FINAL SANITY CHECKS:\n",
      "  Features have reasonable ranges? True\n",
      "  No single feature dominates? True\n",
      "  Model not overfitting badly? True\n",
      "  Performance above random? True\n",
      "\n",
      "=== VALIDATION COMPLETE ===\n"
     ]
    }
   ],
   "source": [
    "### VALIDATION FOR MODEL INTEGRITY ###\n",
    "# This function will run multiple validation tests to ensure model integrity\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def comprehensive_validation(df, clean_df, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Run multiple validation tests to ensure model integrity\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== COMPREHENSIVE MODEL VALIDATION ===\\n\")\n",
    "    \n",
    "    # 1. FEATURE LEAKAGE TEST - Check individual feature power\n",
    "    print(\"1. INDIVIDUAL FEATURE PREDICTIVE POWER:\")\n",
    "    features = X_train.columns\n",
    "    for feature in features:\n",
    "        # Train simple model on just this feature\n",
    "        simple_model = LogisticRegression()\n",
    "        simple_model.fit(X_train[[feature]], y_train)\n",
    "        \n",
    "        train_acc = simple_model.score(X_train[[feature]], y_train)\n",
    "        test_acc = simple_model.score(X_test[[feature]], y_test)\n",
    "        \n",
    "        print(f\"{feature}:\")\n",
    "        print(f\"  Solo Train: {train_acc:.3f}, Solo Test: {test_acc:.3f}, Gap: {test_acc-train_acc:+.3f}\")\n",
    "        \n",
    "        # Flag suspicious features\n",
    "        if test_acc - train_acc > 0.05:\n",
    "            print(f\"   SUSPICIOUS: Test much higher than train!\")\n",
    "        if test_acc > 0.65:\n",
    "            print(f\"   SUSPICIOUS: Single feature too powerful!\")\n",
    "\n",
    "    # 2. TIME-BASED CROSS VALIDATION\n",
    "    print(f\"\\n2. TIME-BASED CROSS VALIDATION:\")\n",
    "    \n",
    "    # Prepare full dataset with proper ordering\n",
    "    full_X = pd.concat([X_train, X_test]).sort_index()\n",
    "    full_y = pd.concat([pd.Series(y_train, index=X_train.index), \n",
    "                       pd.Series(y_test, index=X_test.index)]).sort_index()\n",
    "    \n",
    "    # Time series split (5 folds)\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    cv_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(full_X)):\n",
    "        cv_model = LogisticRegression()\n",
    "        cv_model.fit(full_X.iloc[train_idx], full_y.iloc[train_idx])\n",
    "        \n",
    "        cv_train_acc = cv_model.score(full_X.iloc[train_idx], full_y.iloc[train_idx])\n",
    "        cv_val_acc = cv_model.score(full_X.iloc[val_idx], full_y.iloc[val_idx])\n",
    "        cv_scores.append(cv_val_acc)\n",
    "        \n",
    "        print(f\"  Fold {fold+1}: Train {cv_train_acc:.3f}, Val {cv_val_acc:.3f}, Gap {cv_val_acc-cv_train_acc:+.3f}\")\n",
    "    \n",
    "    cv_mean = np.mean(cv_scores)\n",
    "    cv_std = np.std(cv_scores)\n",
    "    print(f\"  CV Mean: {cv_mean:.3f} ± {cv_std:.3f}\")\n",
    "    \n",
    "    # 3. RANDOM BASELINE TEST\n",
    "    print(f\"\\n3. RANDOM BASELINE COMPARISON:\")\n",
    "    \n",
    "    # Shuffle target to create random baseline\n",
    "    y_train_shuffled = np.random.permutation(y_train)\n",
    "    y_test_shuffled = np.random.permutation(y_test)\n",
    "    \n",
    "    random_model = LogisticRegression()\n",
    "    random_model.fit(X_train, y_train_shuffled)\n",
    "    \n",
    "    random_train_acc = random_model.score(X_train, y_train_shuffled)\n",
    "    random_test_acc = random_model.score(X_test, y_test_shuffled)\n",
    "    \n",
    "    print(f\"Random baseline - Train: {random_train_acc:.3f}, Test: {random_test_acc:.3f}\")\n",
    "    print(f\"Model improvement over random: {test_acc - random_test_acc:.3f}\")\n",
    "    \n",
    "    # 4. FEATURE IMPORTANCE & STABILITY\n",
    "    print(f\"\\n4. FEATURE IMPORTANCE ANALYSIS:\")\n",
    "    \n",
    "    main_model = LogisticRegression()\n",
    "    main_model.fit(X_train, y_train)\n",
    "    \n",
    "    feature_importance = abs(main_model.coef_[0])\n",
    "    feature_names = X_train.columns\n",
    "    \n",
    "    for name, importance in zip(feature_names, feature_importance):\n",
    "        print(f\"  {name}: {importance:.4f}\")\n",
    "    \n",
    "    # Test stability with bootstrap\n",
    "    print(f\"\\n5. MODEL STABILITY TEST (Bootstrap):\")\n",
    "    bootstrap_scores = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        # Random sample of training data\n",
    "        sample_idx = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        X_boot = X_train.iloc[sample_idx]\n",
    "        y_boot = y_train.iloc[sample_idx]\n",
    "        \n",
    "        boot_model = LogisticRegression()\n",
    "        boot_model.fit(X_boot, y_boot)\n",
    "        boot_score = boot_model.score(X_test, y_test)\n",
    "        bootstrap_scores.append(boot_score)\n",
    "    \n",
    "    boot_mean = np.mean(bootstrap_scores)\n",
    "    boot_std = np.std(bootstrap_scores)\n",
    "    print(f\"  Bootstrap test scores: {boot_mean:.3f} ± {boot_std:.3f}\")\n",
    "    print(f\"  Your model vs bootstrap mean: {test_acc - boot_mean:+.3f}\")\n",
    "    \n",
    "    # 6. H2H SPECIFIC VALIDATION\n",
    "    if 'h2h_advantage' in features:\n",
    "        print(f\"\\n6. H2H VALIDATION:\")\n",
    "        \n",
    "        # Check H2H distribution by time period\n",
    "        early_matches = clean_df[clean_df['date'] < '2024-01-01']\n",
    "        recent_matches = clean_df[clean_df['date'] >= '2024-01-01']\n",
    "        \n",
    "        if len(early_matches) > 0 and len(recent_matches) > 0:\n",
    "            print(f\"  Early period H2H mean: {early_matches['h2h_advantage'].mean():.3f}\")\n",
    "            print(f\"  Recent period H2H mean: {recent_matches['h2h_advantage'].mean():.3f}\")\n",
    "            \n",
    "            # Check how often H2H is default (0.5) vs real data\n",
    "            early_default_pct = (early_matches['h2h_advantage'] == 0.5).mean()\n",
    "            recent_default_pct = (recent_matches['h2h_advantage'] == 0.5).mean()\n",
    "            \n",
    "            print(f\"  Early period default H2H: {early_default_pct:.1%}\")\n",
    "            print(f\"  Recent period default H2H: {recent_default_pct:.1%}\")\n",
    "    \n",
    "    # 7. FINAL SANITY CHECKS\n",
    "    print(f\"\\n7. FINAL SANITY CHECKS:\")\n",
    "    print(f\"  Features have reasonable ranges? {all(abs(X_train.mean()) < 10)}\")\n",
    "    print(f\"  No single feature dominates? {max(feature_importance) < 5}\")\n",
    "    print(f\"  Model not overfitting badly? {abs(test_acc - train_acc) < 0.1}\")\n",
    "    print(f\"  Performance above random? {test_acc > 0.52}\")\n",
    "    \n",
    "    print(f\"\\n=== VALIDATION COMPLETE ===\")\n",
    "    \n",
    "    return cv_scores, bootstrap_scores\n",
    "\n",
    "# Usage:\n",
    "\n",
    "train_acc = 0.557  # Most recent train accuracy\n",
    "test_acc = 0.605  # Most recent test accuracy\n",
    "\n",
    "cv_scores, boot_scores = comprehensive_validation(df, clean_df, X_train, X_test, y_train_numeric, y_test_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "6cb269fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close matches accuracy: result\n",
      "L    141\n",
      "W    134\n",
      "Name: count, dtype: int64\n",
      "r2_bins\n",
      "(-0.73, -0.416]     0.200000\n",
      "(-0.416, -0.104]    0.417040\n",
      "(-0.104, 0.207]     0.541417\n",
      "(0.207, 0.519]      0.582915\n",
      "(0.519, 0.831]      0.739130\n",
      "Name: result, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/0ttm8wnn2hx0rydcd55zy81r0000gn/T/ipykernel_15247/249143216.py:8: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  print(df.groupby('r2_bins')['result'].apply(lambda x: (x=='W').mean()))\n"
     ]
    }
   ],
   "source": [
    "### Testing for R2 Score validity ###\n",
    "#close matchups only\n",
    "close_matches = clean_df[abs(clean_df['r2_advantage']) < 0.05]  # Very close R2\n",
    "print(f\"Close matches accuracy: {close_matches['result'].value_counts()}\")\n",
    "\n",
    "# accuracy by R2_advantage bins\n",
    "df['r2_bins'] = pd.cut(df['r2_advantage'], bins=5)\n",
    "print(df.groupby('r2_bins')['result'].apply(lambda x: (x=='W').mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "valorant-ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
